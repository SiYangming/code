---
title: "并行化训练模型"
output: html_notebook
---

```{python}
# Otto, tune number of threads
from pandas import read_csv
from xgboost import XGBClassifier
from sklearn.preprocessing import LabelEncoder
from time import time
from matplotlib import pyplot 
# load data  
data = read_csv('train.csv')
dataset = data.values
# split data into X and y
X = dataset[:,0:94]
y = dataset[:,94]
# encode string class values as integers
label_encoded_y = LabelEncoder().fit_transform(y)
# evaluate the effect of the number of threads
results = []
num_threads = [1, 2, 3, 4]
for n in num_threads:
    start = time()
    model = XGBClassifier(nthread=n)
    model.fit(X, label_encoded_y)
    elapsed = time() - start
    print(n, elapsed)
    results.append(elapsed)
```

```{python}
# plot results
pyplot.plot(num_threads, results)  
pyplot.ylabel('Speed (seconds)')  
pyplot.xlabel('Number of Threads')  
pyplot.title('XGBoost Training Speed vs Number of Threads') 
pyplot.show()
```


```{python}
# prepare cross validation  
kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)  
# Single Thread XGBoost, Parallel Thread CV  
start = time()  
model = XGBClassifier(nthread=1)  
results = cross_val_score(model, X, label_encoded_y, cv=kfold, scoring='neg_log_loss', n_jobs=-1)  
elapsed = time() - start  
print("Single Thread XGBoost, Parallel Thread CV: %f" % (elapsed))  
```

```{python}
# Parallel Thread XGBoost, Single Thread CV  
start = time()  
model = XGBClassifier(nthread=-1)  
results = cross_val_score(model, X, label_encoded_y, cv=kfold, scoring='neg_log_loss', n_jobs=1)  
elapsed = time() - start  
print("Parallel Thread XGBoost, Single Thread CV: %f" % (elapsed))  
```

```{python}
# Parallel Thread XGBoost and CV  
start = time()  
model = XGBClassifier(nthread=-1)  
results = cross_val_score(model, X, label_encoded_y, cv=kfold, scoring='neg_log_loss', n_jobs=-1)
elapsed = time() - start
print("Parallel Thread XGBoost and CV: %f" % (elapsed))
```

